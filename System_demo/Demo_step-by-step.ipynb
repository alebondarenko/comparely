{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative question answering demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External resourses required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 -m nltk.downloader stopwords\n",
    "!python3 -m nltk.downloader universal_tagset\n",
    "!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading [trained models](https://drive.google.com/open?id=1JTtQ6HuSddqAxgXueFQunoaTuknSN7p6) from google drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-08 17:33:31--  https://docs.google.com/uc?export=download&confirm=geV6&id=1JTtQ6HuSddqAxgXueFQunoaTuknSN7p6\n",
      "Resolving docs.google.com (docs.google.com)... 173.194.73.194, 2a00:1450:4010:c03::c2\n",
      "Connecting to docs.google.com (docs.google.com)|173.194.73.194|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-0s-5s-docs.googleusercontent.com/docs/securesc/7ia27re84neq8nk3h6q4aciftspfnri0/65nk291gg3bpupt14iqk2q5s9o5somp7/1588948350000/13476312262238289650/10998875876866526155Z/1JTtQ6HuSddqAxgXueFQunoaTuknSN7p6?e=download [following]\n",
      "--2020-05-08 17:33:31--  https://doc-0s-5s-docs.googleusercontent.com/docs/securesc/7ia27re84neq8nk3h6q4aciftspfnri0/65nk291gg3bpupt14iqk2q5s9o5somp7/1588948350000/13476312262238289650/10998875876866526155Z/1JTtQ6HuSddqAxgXueFQunoaTuknSN7p6?e=download\n",
      "Resolving doc-0s-5s-docs.googleusercontent.com (doc-0s-5s-docs.googleusercontent.com)... 64.233.163.132, 2a00:1450:4010:c0b::84\n",
      "Connecting to doc-0s-5s-docs.googleusercontent.com (doc-0s-5s-docs.googleusercontent.com)|64.233.163.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://docs.google.com/nonceSigner?nonce=dl774t3gg20h4&continue=https://doc-0s-5s-docs.googleusercontent.com/docs/securesc/7ia27re84neq8nk3h6q4aciftspfnri0/65nk291gg3bpupt14iqk2q5s9o5somp7/1588948350000/13476312262238289650/10998875876866526155Z/1JTtQ6HuSddqAxgXueFQunoaTuknSN7p6?e%3Ddownload&hash=30hneo87k0g434eghefo2pc4r8iu8p38 [following]\n",
      "--2020-05-08 17:33:32--  https://docs.google.com/nonceSigner?nonce=dl774t3gg20h4&continue=https://doc-0s-5s-docs.googleusercontent.com/docs/securesc/7ia27re84neq8nk3h6q4aciftspfnri0/65nk291gg3bpupt14iqk2q5s9o5somp7/1588948350000/13476312262238289650/10998875876866526155Z/1JTtQ6HuSddqAxgXueFQunoaTuknSN7p6?e%3Ddownload&hash=30hneo87k0g434eghefo2pc4r8iu8p38\n",
      "Connecting to docs.google.com (docs.google.com)|173.194.73.194|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://doc-0s-5s-docs.googleusercontent.com/docs/securesc/7ia27re84neq8nk3h6q4aciftspfnri0/65nk291gg3bpupt14iqk2q5s9o5somp7/1588948350000/13476312262238289650/10998875876866526155Z/1JTtQ6HuSddqAxgXueFQunoaTuknSN7p6?e=download&nonce=dl774t3gg20h4&user=10998875876866526155Z&hash=f6p0k3c4ir79i34pfk39vqu79gcjistp [following]\n",
      "--2020-05-08 17:33:32--  https://doc-0s-5s-docs.googleusercontent.com/docs/securesc/7ia27re84neq8nk3h6q4aciftspfnri0/65nk291gg3bpupt14iqk2q5s9o5somp7/1588948350000/13476312262238289650/10998875876866526155Z/1JTtQ6HuSddqAxgXueFQunoaTuknSN7p6?e=download&nonce=dl774t3gg20h4&user=10998875876866526155Z&hash=f6p0k3c4ir79i34pfk39vqu79gcjistp\n",
      "Connecting to doc-0s-5s-docs.googleusercontent.com (doc-0s-5s-docs.googleusercontent.com)|64.233.163.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘model_files.zip’\n",
      "\n",
      "model_files.zip         [  <=>               ]   1.63G  9.44MB/s    in 8m 2s   \n",
      "\n",
      "2020-05-08 17:41:35 (3.47 MB/s) - ‘model_files.zip’ saved [1754327305]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1JTtQ6HuSddqAxgXueFQunoaTuknSN7p6' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1JTtQ6HuSddqAxgXueFQunoaTuknSN7p6\" -O model_files.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzipping the archive and moving the files to proper places:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  model_files.zip\n",
      "   creating: model_files/\n",
      "   creating: model_files/bert/\n",
      "  inflating: model_files/bert/pytorch_model.bin  \n",
      "   creating: model_files/elmo/\n",
      "  inflating: model_files/elmo/elmo+linreg.bin  \n",
      "   creating: model_files/infersent/\n",
      "  inflating: model_files/infersent/infersent+xgboost.bin  \n",
      "   creating: model_files/seq_lab/\n",
      "   creating: model_files/seq_lab/BERT_seq_lab/\n",
      "  inflating: model_files/seq_lab/BERT_seq_lab/pytorch_model.bin  \n",
      "   creating: model_files/seq_lab/LSTMCRF_seq_lab/\n",
      "  inflating: model_files/seq_lab/LSTMCRF_seq_lab/pytorch_model.bin  \n",
      "  inflating: model_files/seq_lab/LSTMCRF_seq_lab/vocab.pkl  \n",
      "   creating: model_files/w2v/\n",
      "  inflating: model_files/w2v/asp_clf.pkl  \n"
     ]
    }
   ],
   "source": [
    "!unzip model_files.zip\n",
    "!mv model_files/bert/pytorch_model.bin bert/pytorch_model.bin\n",
    "!mv model_files/elmo/elmo+linreg.bin elmo/elmo+linreg.bin\n",
    "!mv model_files/infersent/infersent+xgboost.bin infersent/infersent+xgboost.bin\n",
    "!mv model_files/seq_lab/BERT_seq_lab/pytorch_model.bin seq_lab/BERT_seq_lab/pytorch_model.bin\n",
    "!mv model_files/seq_lab/LSTMCRF_seq_lab/pytorch_model.bin seq_lab/LSTMCRF_seq_lab/pytorch_model.bin\n",
    "!mv model_files/seq_lab/LSTMCRF_seq_lab/vocab.pkl seq_lab/LSTMCRF_seq_lab/vocab.pkl\n",
    "!mv model_files/w2v/asp_clf.pkl w2v/asp_clf.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole pipeline in three cells to provide an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing comparative sentences classifier\n",
      "Initializing aspect classifier\n"
     ]
    }
   ],
   "source": [
    "# possible args for comp_sent_clf_name: 'bow+xgboost', 'infersent+xgboost', 'elmo+linreg', 'bert'\n",
    "# possible args for seq_labeller_name: None, 'lstmcrftagger', 'berttagger'\n",
    "# if seq_labeller_name is None, keywords approach will be used\n",
    "pl = Pipeline(comp_sent_clf_name='infersent+xgboost', seq_labeller_name='berttagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting Elasticsearch\n",
      "Preparing sentences\n",
      "Classifying comparative sentences\n",
      "Sequence labelling\n",
      "Result:\n",
      "python: ['older', 'easier to read', 'easier to learn', 'easier', 'simpler', 'complex', 'easier to program in', 'quicker to write code']\n",
      "java: ['faster', 'stronger']\n"
     ]
    }
   ],
   "source": [
    "obj_a, obj_b, obj_a_aspects, obj_b_aspects = pl.get_structured_answer(\"python\", \"java\")\n",
    "print(\"Result:\")\n",
    "print(f\"{obj_a}: {obj_a_aspects}\")\n",
    "print(f\"{obj_b}: {obj_b_aspects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting Elasticsearch\n",
      "Preparing sentences\n",
      "Classifying comparative sentences\n",
      "Looking for keyphrases\n",
      "Predicting good aspects\n",
      "Result:\n",
      "xbox: ['play', 'control', 'graphics', 'comparison', 'better situation', 'greater sales', 'form', 'powerful', 'console sales', 'offense', 'much healty']\n",
      "play station: ['much', 'smart design', 'better target', 'free', 'reliable', 'much video games', 'superior machine', 'good old play', 'speed', 'free games', 'better graphics', 'cheaper', 'better deal', 'touch screen', 'liberation', 'resistance bs', 'bad system', 'fun', 'overall']\n"
     ]
    }
   ],
   "source": [
    "obj_a, obj_b, obj_a_aspects, obj_b_aspects = pl.get_structured_answer(\"xbox\", \"play station\")\n",
    "print(\"Result:\")\n",
    "print(f\"{obj_a}: {obj_a_aspects}\")\n",
    "print(f\"{obj_b}: {obj_b_aspects}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pke\n",
    "from pke.unsupervised import MultipartiteRank\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import joblib\n",
    "import torch\n",
    "from CompSentClf import CompSentClf\n",
    "from seq_lab.SeqLabeller import SeqLabeller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input two objects to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_a = \"python\"\n",
    "obj_b = \"java\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_a = obj_a.lower().strip()\n",
    "obj_b = obj_b.lower().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for sentences, containing the requested objects in Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in user and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_elasticsearch(obj_a, obj_b, user, password):\n",
    "    url = 'http://ltdemos.informatik.uni-hamburg.de/depcc-index/_search?q='\n",
    "    url += 'text:\\\"{}\\\"%20AND%20\\\"{}\\\"'.format(obj_a, obj_b)\n",
    "\n",
    "    size = 10000\n",
    "    \n",
    "    url += '&from=0&size={}'.format(size)\n",
    "    response = requests.get(url, auth=HTTPBasicAuth(user, password))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write down the name and password for elasticSearch\n",
    "name = \"reader\"\n",
    "password = \"reader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_compl = request_elasticsearch(obj_a, obj_b, name, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing sentences for classificator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences(es_json, aggregate_duplicates=False):\n",
    "    try:\n",
    "        hits = es_json.json()['hits']['hits']\n",
    "    except KeyError:\n",
    "        return []\n",
    "    sentences = []\n",
    "    seen_sentences = set()\n",
    "    for hit in hits:\n",
    "        source = hit['_source']\n",
    "        text = source['text']\n",
    "\n",
    "        if not aggregate_duplicates:\n",
    "            if (text.lower()) not in seen_sentences:\n",
    "                seen_sentences.add(text.lower())\n",
    "                sentences.append(text)\n",
    "        else:\n",
    "            sentences.append(text)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "def remove_questions(sentences):\n",
    "    sentences_to_delete = []\n",
    "    for sentence in sentences:\n",
    "        if '?' in sentence:\n",
    "            sentences_to_delete.append(sentence)\n",
    "    for sentence in sentences_to_delete:\n",
    "        del sentences[sentences.index(sentence)]\n",
    "    return sentences\n",
    "\n",
    "def get_regEx(sequence):\n",
    "    return re.compile('\\\\b{}\\\\b|\\\\b{}\\\\b'.format(re.escape(sequence), re.sub('[^a-zA-Z0-9 ]', ' ', sequence)), re.IGNORECASE)\n",
    "\n",
    "def find_pos_in_sentence(sequence, sentence):\n",
    "    regEx = get_regEx(sequence)\n",
    "    match = regEx.search(sentence)    \n",
    "    if match == None:\n",
    "        match = regEx.search(re.sub(' +',' ', re.sub('[^a-zA-Z0-9 ]', ' ', sentence)))\n",
    "        return match.start() if match != None else -1\n",
    "    else:\n",
    "        return match.start()\n",
    "\n",
    "def prepare_sentence_DF(sentences, obj_a, obj_b):\n",
    "    index = 0\n",
    "    temp_list = []\n",
    "    for sentence in sentences:\n",
    "        pos_a = find_pos_in_sentence(obj_a, sentence)\n",
    "        pos_b = find_pos_in_sentence(obj_b, sentence)\n",
    "        if pos_a < pos_b:\n",
    "            temp_list.append([obj_a, obj_b, sentence])\n",
    "        else:\n",
    "            temp_list.append([obj_b, obj_a, sentence])\n",
    "        index += 1\n",
    "    sentence_df = pd.DataFrame.from_records(temp_list, columns=['object_a', 'object_b', 'sentence'])\n",
    "\n",
    "    return sentence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = extract_sentences(json_compl)\n",
    "remove_questions(all_sentences)\n",
    "prepared_sentences = prepare_sentence_DF(all_sentences, obj_a, obj_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_a</th>\n",
       "      <th>object_b</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>Software Terms:  Java, Programming, Source Cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>Java , Ruby, Python, Java,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>As Java devours Python, Python also devours Java.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>compare Java to Python, not Java + JVM to Python.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>Python is not Java, and Java is not Python.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  object_a object_b                                           sentence\n",
       "0     java   python  Software Terms:  Java, Programming, Source Cod...\n",
       "1     java   python                         Java , Ruby, Python, Java,\n",
       "2     java   python  As Java devours Python, Python also devours Java.\n",
       "3     java   python  compare Java to Python, not Java + JVM to Python.\n",
       "4   python     java        Python is not Java, and Java is not Python."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using classificator of comparative sentences\n",
    "The classificator is used in CAM system:  \n",
    "Paper: https://arxiv.org/abs/1901.05041  \n",
    "Github: https://github.com/uhh-lt/cam/  \n",
    "\n",
    "The classifier takes 2 compared objects and a sentence as an input.\n",
    "The output is one of 3 classes:\n",
    "- NONE - the sentence does not have comparison in it\n",
    "- BETTER - the first object in a sentence is better than the second\n",
    "- WORSE - the first object in a sentence is worse than the second  \n",
    "\n",
    "Paper: https://arxiv.org/abs/1809.06152\n",
    "\n",
    "Models from the paper:\n",
    "- BOW+XGBoost\n",
    "- InferSent+XGBoost\n",
    "\n",
    "The other options available:\n",
    "- ELMo+LinReg\n",
    "- BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bow+xgboost\" # 'bow+xgboost', 'infersent+xgboost', 'elmo+linreg', 'bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CompSentClf(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_results = clf.classify_sentences(prepared_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need the sentences without comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_a</th>\n",
       "      <th>object_b</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>Python isn't Java.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>But Python isn't Java.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>python than for java.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>Python isn't Java and you shouldn't try to wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>Python, instead of Java).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5232</td>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>(At this point, I know more Java than Python.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5274</td>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>throw a Python RuntimeError instead of a Java ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5330</td>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>Java is a whole lot more predictible than Python.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5385</td>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>net.degreedays.api in Java is equivalent to de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5441</td>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>Java isn't just Python without the cool langua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     object_a object_b                                           sentence\n",
       "81     python     java                                 Python isn't Java.\n",
       "104    python     java                             But Python isn't Java.\n",
       "144    python     java                              python than for java.\n",
       "221    python     java  Python isn't Java and you shouldn't try to wri...\n",
       "296    python     java                          Python, instead of Java).\n",
       "...       ...      ...                                                ...\n",
       "5232     java   python     (At this point, I know more Java than Python.)\n",
       "5274   python     java  throw a Python RuntimeError instead of a Java ...\n",
       "5330     java   python  Java is a whole lot more predictible than Python.\n",
       "5385     java   python  net.degreedays.api in Java is equivalent to de...\n",
       "5441     java   python  Java isn't just Python without the cool langua...\n",
       "\n",
       "[155 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_sentences[classification_results['max'] != 'NONE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniting the comparative sentences and results of classification into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_sentences = prepared_sentences[classification_results['max'] != 'NONE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/.local/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "comparative_sentences['max'] = classification_results[classification_results['max'] != 'NONE']['max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_a</th>\n",
       "      <th>object_b</th>\n",
       "      <th>sentence</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>Python isn't Java.</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>But Python isn't Java.</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>python than for java.</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>Python isn't Java and you shouldn't try to wri...</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>Python, instead of Java).</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5232</td>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>(At this point, I know more Java than Python.)</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5274</td>\n",
       "      <td>python</td>\n",
       "      <td>java</td>\n",
       "      <td>throw a Python RuntimeError instead of a Java ...</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5330</td>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>Java is a whole lot more predictible than Python.</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5385</td>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>net.degreedays.api in Java is equivalent to de...</td>\n",
       "      <td>BETTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5441</td>\n",
       "      <td>java</td>\n",
       "      <td>python</td>\n",
       "      <td>Java isn't just Python without the cool langua...</td>\n",
       "      <td>WORSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     object_a object_b                                           sentence  \\\n",
       "81     python     java                                 Python isn't Java.   \n",
       "104    python     java                             But Python isn't Java.   \n",
       "144    python     java                              python than for java.   \n",
       "221    python     java  Python isn't Java and you shouldn't try to wri...   \n",
       "296    python     java                          Python, instead of Java).   \n",
       "...       ...      ...                                                ...   \n",
       "5232     java   python     (At this point, I know more Java than Python.)   \n",
       "5274   python     java  throw a Python RuntimeError instead of a Java ...   \n",
       "5330     java   python  Java is a whole lot more predictible than Python.   \n",
       "5385     java   python  net.degreedays.api in Java is equivalent to de...   \n",
       "5441     java   python  Java isn't just Python without the cool langua...   \n",
       "\n",
       "         max  \n",
       "81    BETTER  \n",
       "104   BETTER  \n",
       "144   BETTER  \n",
       "221   BETTER  \n",
       "296   BETTER  \n",
       "...      ...  \n",
       "5232  BETTER  \n",
       "5274  BETTER  \n",
       "5330  BETTER  \n",
       "5385  BETTER  \n",
       "5441   WORSE  \n",
       "\n",
       "[155 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting aspects from gathered sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords approach\n",
    "We unite the sentences into a single document and look for keywords in that document using PKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = prepared_sentences[classification_results['max'] != 'NONE']['sentence'].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extractor = MultipartiteRank()\n",
    "extractor.load_document(input=text, language=\"en\", normalization='stemming')\n",
    "\n",
    "extractor.candidate_selection(pos={'NOUN', 'PROPN', 'ADJ'})\n",
    "\n",
    "extractor.candidate_weighting()\n",
    "\n",
    "keyphrases = extractor.get_n_best(n=-1, stemming=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('python', 0.21973674959244296),\n",
       " ('java', 0.2042764442818003),\n",
       " ('faster', 0.014932241840394536),\n",
       " ('easier', 0.01261451070763693),\n",
       " ('slower', 0.009933512569054453),\n",
       " ('better', 0.009375573341228096),\n",
       " ('equivalent', 0.008914757023569454),\n",
       " ('java programs', 0.00867398313325556),\n",
       " ('many ways', 0.008535753833617968),\n",
       " ('popular', 0.008259124756198923),\n",
       " ('python code', 0.007928614854966968),\n",
       " ('language', 0.00783928454007348),\n",
       " ('closer', 0.007038364945303477),\n",
       " ('scala performance', 0.006716068876988277),\n",
       " ('older', 0.006564064343323661),\n",
       " ('syntax', 0.006443130202768127),\n",
       " ('ruby', 0.006339968885611265),\n",
       " ('times', 0.005936204106738509),\n",
       " ('hells', 0.00588300428189334),\n",
       " ('shorter', 0.005729272006915879),\n",
       " ('interpreted', 0.0056786424202054445),\n",
       " ('cool', 0.005491690978292079),\n",
       " ('much', 0.005415352088287819),\n",
       " ('longer time', 0.004801770093156908),\n",
       " ('harder', 0.0046633036637127165),\n",
       " ('java implementation', 0.004645191497805674),\n",
       " ('simpler syntax', 0.004635334947390272),\n",
       " ('final parting shot', 0.004628256437319971),\n",
       " ('people', 0.004563000819160256),\n",
       " ('jobs', 0.0045547703881115295),\n",
       " ('comparable', 0.004553788193319091),\n",
       " ('compile python', 0.004520493280682884),\n",
       " ('similar', 0.0044275886300151526),\n",
       " ('concurrency', 0.004387160288579381),\n",
       " ('easy', 0.004357821518820673),\n",
       " ('popular replacement', 0.004346071797475847),\n",
       " ('jython', 0.0043223697049273365),\n",
       " ('mature', 0.004274721761511636),\n",
       " ('general language preference', 0.0042617237551332105),\n",
       " ('version', 0.004245461306270561),\n",
       " ('complex one', 0.004226400423383624),\n",
       " ('apps', 0.004223377679428619),\n",
       " ('things', 0.004198806092690687),\n",
       " ('smaller', 0.004115016107222225),\n",
       " ('python programmers', 0.004107046170427044),\n",
       " ('python syntax', 0.004103548300785847),\n",
       " ('code', 0.004088813583278288),\n",
       " ('least', 0.004071060643526857),\n",
       " ('perl', 0.004019367643305075),\n",
       " ('lot', 0.0039159533210229615),\n",
       " ('java programmers', 0.0038650119443820125),\n",
       " ('main point', 0.0036926555014436587),\n",
       " ('python interpreter', 0.0036099714577181737),\n",
       " ('python runtime', 0.003411587515242219),\n",
       " ('googling java classes', 0.003363057091408576),\n",
       " ('inferior', 0.0031129698061098505),\n",
       " ('longer', 0.003065725422195175),\n",
       " ('simple', 0.0030648582969146554),\n",
       " ('better programmers', 0.0029613436782182064),\n",
       " ('imitation', 0.00295053336730396),\n",
       " ('productivity', 0.002914800074604394),\n",
       " ('style package structure', 0.0029009522587603066),\n",
       " ('compliant', 0.0028613746252937546),\n",
       " ('performance', 0.0028357509018760805),\n",
       " ('natural', 0.002826801186769707),\n",
       " ('better language', 0.00278710406878442),\n",
       " ('assignment', 0.0027800499659843925),\n",
       " ('bad', 0.0027780863306587364),\n",
       " ('work', 0.00276864656822635),\n",
       " ('batteries', 0.0027663541305692862),\n",
       " ('market share', 0.002754710281953633),\n",
       " ('netflix', 0.0027450970834077084),\n",
       " ('quicker', 0.002734927096765159),\n",
       " ('python jobs', 0.0027217303604762824),\n",
       " ('tcl', 0.0027166365925204283),\n",
       " ('way', 0.002702701246459401),\n",
       " ('jpython', 0.0026905027208528227),\n",
       " ('code samples', 0.0026853525396394605),\n",
       " ('expressive', 0.002684494392165872),\n",
       " ('dalvik', 0.002678370223399931),\n",
       " ('extra credit', 0.002677992060798729),\n",
       " ('compact', 0.002668630396955198),\n",
       " ('worse', 0.0026453253575592097),\n",
       " ('slow', 0.0026419956317559785),\n",
       " ('many ways similar', 0.002637496743797217),\n",
       " ('implementation', 0.002632494578216238),\n",
       " ('significant advantages', 0.002625311896921176),\n",
       " ('java memory management', 0.0026252961585001527),\n",
       " ('book', 0.002608049185652415),\n",
       " ('something', 0.0025986933594471535),\n",
       " ('python java 8x faster', 0.0025971687192469653),\n",
       " ('python memory model', 0.0025932953608410795),\n",
       " ('compile', 0.0025878069158286844),\n",
       " ('java performance wise', 0.0025800348378415424),\n",
       " ('rapid application development', 0.0025517694218886266),\n",
       " ('part', 0.00254732760258866),\n",
       " ('mixed blessing', 0.002543426570860544),\n",
       " ('exceptions', 0.0025429873366468693),\n",
       " ('simpler', 0.002541848210980741),\n",
       " ('java first', 0.0025397809554040672),\n",
       " ('insane', 0.002539278473241584),\n",
       " ('keyword arguments', 0.0025327552099372133),\n",
       " ('expressive language', 0.0025315324765228854),\n",
       " ('appy', 0.002531299025165616),\n",
       " ('optimizations', 0.002524956401032925),\n",
       " ('polymorphism', 0.002517431806159231),\n",
       " ('overloading feature', 0.002510843571922251),\n",
       " ('stronger', 0.002508073879722374),\n",
       " ('secs', 0.0025072337963141025),\n",
       " ('javascript', 0.0024987871108647676),\n",
       " ('respects', 0.0024966695158652403),\n",
       " ('fast', 0.002491318466182628),\n",
       " ('python version', 0.002489996759441993),\n",
       " ('autocmd filetype java nnoremap', 0.0024868290677883295),\n",
       " ('cool language', 0.0024800998179682994),\n",
       " ('late binding', 0.0024769266730385302),\n",
       " ('consistent', 0.002469355941056987),\n",
       " ('general', 0.0024655391875494427),\n",
       " ('site', 0.0024640900768129206),\n",
       " ('libraries', 0.0024494584881282287),\n",
       " ('platform', 0.0024368868707873434),\n",
       " ('useful', 0.0024283948609142504),\n",
       " ('complaints', 0.0024217889110786884),\n",
       " ('python alternate exchange tests', 0.0024186163346554927),\n",
       " ('define operators', 0.002416264292511356),\n",
       " ('way java', 0.0024051673476113726),\n",
       " ('higher', 0.002398738042262069),\n",
       " ('old', 0.002388722238595475),\n",
       " ('boeing', 0.0023873084278685087),\n",
       " ('java java', 0.0023713670260800154),\n",
       " ('dynamic language features', 0.002367060561846471),\n",
       " ('predictible', 0.0023594956431117926),\n",
       " ('programs', 0.002358630210541758),\n",
       " ('java apps', 0.0023530071141433873),\n",
       " ('smalltalk', 0.002346066405935585),\n",
       " ('maturity level', 0.002343182604968522),\n",
       " ('java renderers', 0.0023396900954042307),\n",
       " ('python ide tools', 0.002339202446319905),\n",
       " ('anything', 0.002338214945456438),\n",
       " ('python programs', 0.002336694221087059),\n",
       " ('whole lot', 0.002326889361526382),\n",
       " ('java strings', 0.0023114711669072674),\n",
       " ('equivalent java program', 0.002310949721806039),\n",
       " ('matlab', 0.002295451809560084),\n",
       " ('possible', 0.0022718067000883128),\n",
       " ('virtual machine', 0.0022587653354396325),\n",
       " ('equivalent python programs', 0.002249452939435378),\n",
       " ('first language', 0.0022466599836273946),\n",
       " ('impossible', 0.0021973980094179084),\n",
       " ('python renderers', 0.0021449771511958733),\n",
       " ('java type', 0.0021374639182277534),\n",
       " ('python one', 0.0020963297788720147),\n",
       " ('dynamic python', 0.0020955903334500692),\n",
       " ('easier ways', 0.002090305769343108),\n",
       " ('java 8x', 0.002081426371122418),\n",
       " ('java keywords', 0.0020508948142768657),\n",
       " ('python keywords', 0.002048535311604488),\n",
       " ('point', 0.002042543863926649),\n",
       " ('java runtime', 0.002041402527493816),\n",
       " ('python strings', 0.002031544196102044),\n",
       " ('java guis', 0.0020188388714404214),\n",
       " ('python java', 0.0020083439262790297),\n",
       " ('java circa', 0.0019538243041698454),\n",
       " ('java broker', 0.0018490028174419214),\n",
       " ('java stackoverflowerror', 0.0018450591300414616),\n",
       " ('cool language features', 0.001806702908940798)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyphrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the keyphrases don't look like aspects we need. To extract the needed aspects we use a classifier which is trained to find good aspects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and preprocessing sentences for training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"object_a\", \"object_b\", \"aspect\", \"most_frequent_rating\", \"sentence\"]\n",
    "df_train = pd.read_csv(\"classification_fine_grained/train_clf_fine_grained.csv\", header=None, names=names)\n",
    "df_test = pd.read_csv(\"classification_fine_grained/test_clf_fine_grained.csv\", header=None, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_for_binary(data):\n",
    "    return (data['most_frequent_rating'] != 'BAD').astype('float32').to_numpy()\n",
    "\n",
    "y_train = get_output_for_binary(df_train)\n",
    "y_test = get_output_for_binary(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To vectorise the sentences we use Word2Vec:  \n",
    "Input of the classifier is a concatenation of 4 embeddings:\n",
    "- object a embedding\n",
    "- object b embedding\n",
    "- aspect embedding\n",
    "- sentence embedding  \n",
    "\n",
    "For sentence embedding we use mean of embeddings of its words.  \n",
    "So, considering w2v dimensionality, we have vecctors of size 1200 as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from w2v.w2v_feature import initialize_w2v, W2VFeature\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "w2v_model = initialize_w2v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def report_scores(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    pr = precision_score(y, y_pred, average='weighted')\n",
    "    re = recall_score(y, y_pred, average='weighted')\n",
    "    f1 = f1_score(y, y_pred, average='weighted')\n",
    "    f1_bad, f1_good = f1_score(y, y_pred, average=None)\n",
    "    print(\"Accuracy: {:.2f}\".format(acc * 100))\n",
    "    print(\"Precision: {:.2f}\".format(pr * 100))\n",
    "    print(\"Recall: {:.2f}\".format(re * 100))\n",
    "    print(\"F1: {:.2f}\".format(f1 * 100))\n",
    "    print(\"F1 GOOD: {:.2f}\".format(f1_good * 100))\n",
    "    print(\"F1 BAD: {:.2f}\".format(f1_bad * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.91\n",
      "Precision: 81.99\n",
      "Recall: 81.91\n",
      "F1: 81.89\n",
      "F1 GOOD: 82.43\n",
      "F1 BAD: 81.36\n"
     ]
    }
   ],
   "source": [
    "pl = make_pipeline(W2VFeature(w2v_model), SVC(kernel='linear', gamma='auto'))\n",
    "fitted = pl.fit(df_train, y_train)\n",
    "report_scores(fitted, df_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the classifier: Support Vector Classifier with a linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'w2v/asp_clf.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w2v/asp_clf.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(fitted[1], filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = make_pipeline(W2VFeature(w2v_model), joblib.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Accuracy: 81.91\n",
      "Precision: 81.99\n",
      "Recall: 81.91\n",
      "F1: 81.89\n",
      "F1 GOOD: 82.43\n",
      "F1 BAD: 81.36\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print(\"Test\")\n",
    "report_scores(loaded_model, df_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have trained a classifier and are going to process our keyphrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process the keyphrases we need a separate dataframe with sentences for each aspect (keyphrase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "asp_df = pd.DataFrame(columns=['object_a', 'object_b', 'aspect', 'sentence', 'max'])\n",
    "forbidden_phrases = [obj_a, obj_b, 'better', 'worse']\n",
    "\n",
    "for index, row in comparative_sentences.iterrows():\n",
    "    sentence = row['sentence']\n",
    "    for (keyphrase, score) in keyphrases:\n",
    "        skip_keyphrase = False\n",
    "        for phrase in forbidden_phrases:\n",
    "            if keyphrase == phrase:\n",
    "                skip_keyphrase = True\n",
    "                break\n",
    "        if not skip_keyphrase:\n",
    "            if keyphrase in sentence:\n",
    "                asp_df = asp_df.append(\n",
    "                    {'object_a': row['object_a'],\n",
    "                     'object_b': row['object_b'],\n",
    "                     'aspect': keyphrase,\n",
    "                     'sentence': row['sentence'],\n",
    "                     'max': row['max'],\n",
    "                    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model.predict(asp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aspects left after classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = asp_df.iloc[np.nonzero(y_pred)[0].tolist()]['aspect'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['faster', 'easier', 'apps', 'syntax', 'simpler syntax', 'simpler',\n",
       "       'performance', 'slower', 'easier ways'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence labelling approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = prepared_sentences[classification_results['max'] != 'NONE']['sentence'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lab_name = 'berttagger'\n",
    "seq_labeller = SeqLabeller(seq_lab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, preds = seq_labeller.get_labels(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "asp_df = pd.DataFrame(columns=['object_a', 'object_b', 'aspect', 'sentence', 'max'])\n",
    "\n",
    "aspects = set()\n",
    "\n",
    "for i, sent in enumerate(words):\n",
    "    for j, word in enumerate(sent):\n",
    "        if preds[i][j] == 'B-PREDFULL':\n",
    "            cur_asp = word\n",
    "            for k in range(j + 1, len(sent)):\n",
    "                if preds[i][k] == 'I-PREDFULL':\n",
    "                    cur_asp = cur_asp + ' ' + sent[k]\n",
    "                else:\n",
    "                    break\n",
    "            aspects.add(cur_asp.lower())\n",
    "            row = comparative_sentences.iloc[i]\n",
    "            asp_df = asp_df.append(\n",
    "                    {'object_a': row['object_a'],\n",
    "                     'object_b': row['object_b'],\n",
    "                     'aspect': cur_asp,\n",
    "                     'sentence': row['sentence'],\n",
    "                     'max': row['max'],\n",
    "                    }, ignore_index=True)\n",
    "            \n",
    "aspects = list(aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simpler',\n",
       " 'easier',\n",
       " 'easier to program in',\n",
       " 'complex',\n",
       " 'easier to learn',\n",
       " 'faster',\n",
       " 'older',\n",
       " 'stronger',\n",
       " 'easier to read',\n",
       " 'quicker to write code']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to specify which aspects belong to which object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_a_aspects = []\n",
    "obj_b_aspects = []\n",
    "for aspect in aspects:\n",
    "    rows = asp_df[asp_df['aspect']==aspect]\n",
    "    if obj_a == rows.iloc[0]['object_a']:\n",
    "        obj_a_aspects.append(aspect)\n",
    "    else:\n",
    "        obj_b_aspects.append(aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simpler',\n",
       " 'easier',\n",
       " 'easier to program in',\n",
       " 'complex',\n",
       " 'easier to learn',\n",
       " 'older',\n",
       " 'easier to read',\n",
       " 'quicker to write code']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_a_aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['faster', 'stronger']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_b_aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winner of comparison is the object which has more aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing_pair = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(obj_a_aspects) > len(obj_b_aspects):\n",
    "    comparing_pair['winner_aspects'] = obj_a_aspects\n",
    "    comparing_pair['loser_aspects'] = obj_b_aspects\n",
    "    comparing_pair['winner'] = obj_a\n",
    "    comparing_pair['loser'] = obj_b\n",
    "else:\n",
    "    comparing_pair['winner_aspects'] = obj_b_aspects\n",
    "    comparing_pair['loser_aspects'] = obj_a_aspects\n",
    "    comparing_pair['winner'] = obj_b\n",
    "    comparing_pair['loser'] = obj_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_generation.template_generation import generate_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'after much thought, I realized that  python is better, because: compile, better language, easier, syntax, simpler syntax, apps, simpler, quicker, performance, slower, easier ways. But you should know that java is: faster, comparable, productivity, bad'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_template(comparing_pair, mode=\"extended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a brief summary using text rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization.textcleaner import split_sentences\n",
    "from gensim.summarization.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = asp_df[asp_df.aspect.isin(aspects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \"\"\n",
    "for row in range (rows.shape[0]):\n",
    "    sentence = asp_df.iloc[row]['sentence'] + \" \"\n",
    "    if sentence not in sentences:\n",
    "        sentences += sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(split_sentences(sentences)) > 10:\n",
    "    summary = str(summarize(sentences, split=False, word_count=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python runs slower than Java .\n",
      "Python isn't just Java without the compile .\n",
      "much slower in python than in java.\n",
      "much slower in python than in java.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/.local/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from Demo import one_liner\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test what the demo by using the oneliner below (it only requires the w2v model)  \n",
    "response - sentence containing aspects of products generated using templates  \n",
    "summary - brief summary of sentences gathered from Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "# w2v_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_a = \"play station\"\n",
    "obj_b = \"xbox\"\n",
    "user = \"reader\" # username in Elasticsearch\n",
    "password = \"reader\" # password in Elasticsearch\n",
    "\n",
    "response, summary = one_liner(obj_a, obj_b, user, password, w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i came to the conclusion that play station is better, because: much, ill, fun abilities, useful, fun, smart design, better target, free, reliable, much video games, bumpers, rubbish, price tag, price, investors, current market dominance, apprehension, order, powerful consoles, candy, stocking, solder toys, bit bigger, x2 inches, numbers, works, cheaper, free games, better deal, better graphics, touch screen, coarse flipping, resistance bs, liberation, bad system, overall. But it will be useful for you to know that xbox is: play, control, graphics, comparison, better situation, greater sales, form, sale, last, bluray drive, disk, trading games, powerful, console sales, size, cheap, best, hard, secure'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One great feature on this then, is the free play station network, which is also much more reliable than Xbox LIVE.\\nPersonally I prefer the Xbox controller and I've heard that live is a more complete online experience than what play station offers.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
