{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwikidata.sparql  import return_sparql_query_results\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting entities of desired objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function making a query to wikidata using SPARQL for getting a list of entities using a string as a name the desired item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_entities(item, limit=10):\n",
    "    query_string = f\"\"\"\n",
    "    SELECT * WHERE {{\n",
    "      ?item wdt:P31 ?instance\n",
    "      SERVICE wikibase:mwapi {{\n",
    "        bd:serviceParam wikibase:api \"EntitySearch\" .\n",
    "        bd:serviceParam wikibase:endpoint \"www.wikidata.org\" .\n",
    "        bd:serviceParam mwapi:search \"{item}\" .\n",
    "        bd:serviceParam mwapi:language \"en\" .\n",
    "        bd:serviceParam mwapi:uselang \"en\" .\n",
    "        bd:serviceParam mwapi:limit {limit} .\n",
    "        ?item wikibase:apiOutputItem mwapi:item .\n",
    "\n",
    "        ?num wikibase:apiOrdinal true.\n",
    "      }}\n",
    "    }} ORDER BY ASC (?num)\n",
    "    \"\"\"\n",
    "#         ?label wikibase:apiOutput \"@label\" .\n",
    "#         ?matchType wikibase:apiOutput \"match/@type\" .\n",
    "#         ?matchLang wikibase:apiOutput \"match/@language\" .\n",
    "#         ?matchText wikibase:apiOutput \"match/@text\"  .\n",
    "#         ?description wikibase:apiOutput \"@description\" .\n",
    "    res = return_sparql_query_results(query_string)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_a = search_entities(\"Python\")\n",
    "res_b = search_entities(\"Java\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function transforms the response from the entity searching query to the dataframe which contains pairs of the following format: Entity - One of the classes of which this entity is an instance. One entity can be an instance of several classes, so some pairs have same entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res2df(res):\n",
    "    df = pd.DataFrame(columns=['entity', 'instance', 'num'])\n",
    "    for row in res[\"results\"][\"bindings\"]:\n",
    "        entity = row[\"item\"][\"value\"].split('/')[-1]\n",
    "        instance = row[\"instance\"][\"value\"].split('/')[-1]\n",
    "        num = row[\"num\"][\"value\"]\n",
    "        df = df.append({'entity': entity, 'instance': instance, 'num': num}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = res2df(res_a)\n",
    "df_b = res2df(res_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for extracting information about entities listed using a query to MediaWiki API. SPARQL does not give the full list of enitities for some reason. You cn check this by comparing the response received from it with web search page results at wikidata.org. Nevertheless, it can be helpful for getting a list of entities for a requested string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(entities):\n",
    "    ids = \"\"\n",
    "    for entity in entities:\n",
    "        ids += entity + \"|\"\n",
    "    ids = ids[:-1]\n",
    "    url = f\"https://www.wikidata.org/w/api.php?action=wbgetentities&ids={ids}&languages=en&format=json\"\n",
    "    response = requests.get(url).json()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the list of entities from json responce received by the previous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_insts_from_json(json):\n",
    "    insts = []\n",
    "    for key, val in json['entities'].items():\n",
    "        insts_json = val['claims']['P31']\n",
    "        inst = []\n",
    "        for inst_json in insts_json:\n",
    "            inst.append(inst_json['mainsnak']['datavalue']['value']['id'])\n",
    "        insts.append(inst)\n",
    "    return insts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for getting the supposedly compared entities by the principle of the majotity of coinciding \"instances\" (the classes of which this entity is an instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_pair(df_a, df_b):\n",
    "    ent_a = df_a['entity'].unique()\n",
    "    ent_b = df_b['entity'].unique()\n",
    "    json_a = get_entities(ent_a)\n",
    "    json_b = get_entities(ent_b)\n",
    "    insts_a = get_insts_from_json(json_a)\n",
    "    insts_b = get_insts_from_json(json_b)\n",
    "    \n",
    "    conc_table = np.zeros((ent_a.shape[0], ent_b.shape[0]))\n",
    "    for ind, val in np.ndenumerate(conc_table):\n",
    "#         inst_a = df_a[df_a['entity'] == ent_a[ind[0]]]['instance']\n",
    "#         inst_b = df_b[df_b['entity'] == ent_b[ind[1]]]['instance']\n",
    "        inst_a = insts_a[ind[0]]\n",
    "        inst_b = insts_b[ind[1]]\n",
    "        common_inst = list(set(inst_a) & set(inst_b))\n",
    "        conc_table[ind] = len(common_inst)\n",
    "    pair = list(np.unravel_index(np.argmax(conc_table), conc_table.shape))\n",
    "    pair[0] = ent_a[pair[0]]\n",
    "    pair[1] = ent_b[pair[1]]\n",
    "    return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q28865', 'Q251']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_pair(df_a, df_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniting the process of searching for entities, corresponding to the compared objects, using string names as input,  into one function. String names -> entity ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings2ids(obj_a, obj_b):\n",
    "    a = search_entities(obj_a)\n",
    "    b = search_entities(obj_b)\n",
    "    a = res2df(a)\n",
    "    b = res2df(b)\n",
    "    ids = get_best_pair(a, b)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q28865', 'Q251']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings2ids(\"python\", \"java\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try another approach based on coinciding pairs of property (entity relation) names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_props_from_json(json):\n",
    "    props = []\n",
    "    for key, val in json['entities'].items():\n",
    "        props_json = val['claims']\n",
    "        prop = []\n",
    "        for k in props_json.keys():\n",
    "            prop.append(k)\n",
    "        props.append(prop)\n",
    "    return props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_a = df_a['entity'].unique()\n",
    "json_a = get_entities(ent_a)\n",
    "props_a = get_props_from_json(json_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_pair(df_a, df_b, criteria='property'):\n",
    "    ent_a = df_a['entity'].unique()\n",
    "    ent_b = df_b['entity'].unique()\n",
    "    json_a = get_entities(ent_a)\n",
    "    json_b = get_entities(ent_b)\n",
    "    if criteria == 'instance':\n",
    "        cr_a = get_insts_from_json(json_a)\n",
    "        cr_b = get_insts_from_json(json_b)\n",
    "    elif criteria == 'property':\n",
    "        cr_a = get_props_from_json(json_a)\n",
    "        cr_b = get_props_from_json(json_b)\n",
    "    \n",
    "    conc_table = np.zeros((ent_a.shape[0], ent_b.shape[0]))\n",
    "    for ind, val in np.ndenumerate(conc_table):\n",
    "#         inst_a = df_a[df_a['entity'] == ent_a[ind[0]]]['instance']\n",
    "#         inst_b = df_b[df_b['entity'] == ent_b[ind[1]]]['instance']\n",
    "        cur_cr_a = cr_a[ind[0]]\n",
    "        cur_cr_b = cr_b[ind[1]]\n",
    "        common_cr = list(set(cur_cr_a) & set(cur_cr_b))\n",
    "        conc_table[ind] = len(common_cr)\n",
    "    pair = list(np.unravel_index(np.argmax(conc_table), conc_table.shape))\n",
    "    ent_info_a = json_a['entities'][ent_a[pair[0]]]\n",
    "    ent_info_b = json_b['entities'][ent_b[pair[1]]]\n",
    "    return ent_a[pair[0]], ent_b[pair[1]], ent_info_a, ent_info_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the concurrernce tables (conc_table variable), we can see that in case of comparing instance the numbers are lower than in case of comparing properties, so outliers are more likely to mess up the choice of entity pair.  \n",
    "\n",
    "Conc_table for instances:  \n",
    "[[2. 0. 0. 0. 0. 0. 0. 0. 0.]  \n",
    " [0. 0. 0. 0. 0. 0. 1. 0. 0.]  \n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0.]  \n",
    " [0. 0. 1. 0. 0. 0. 0. 0. 0.]  \n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0.]  \n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0.]  \n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0.]  \n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0.]  \n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0.]  \n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
    "   \n",
    "Conc_table for properties:  \n",
    "[[28.  9.  4. 15.  2.  3.  2.  2.  3.]  \n",
    " [ 4.  6.  2.  4.  2.  3. 12.  2.  4.]  \n",
    " [ 8. 13.  3.  5.  2.  4.  3.  2.  4.]  \n",
    " [ 3.  3.  4.  2.  1.  2.  2.  1.  2.]  \n",
    " [ 9.  3.  2. 11.  2.  2.  2.  2.  3.]  \n",
    " [ 4.  5.  2.  5.  2.  3.  3.  2.  4.]  \n",
    " [ 1.  2.  1.  1.  2.  1.  1.  1.  1.]  \n",
    " [ 2.  1.  1.  2.  1.  1.  1.  1.  1.]  \n",
    " [ 3.  3.  3.  3.  1.  3.  2.  1.  2.]  \n",
    " [ 2.  1.  1.  1.  1.  1.  1.  1.  1.]]  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Q28865', 'Q251')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_id_a, ent_id_b, ent_info_a, ent_info_b = get_best_pair(df_a, df_b, criteria='property')\n",
    "ent_id_a, ent_id_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings2ids(obj_a, obj_b, criteria='property'):\n",
    "    a = search_entities(obj_a)\n",
    "    b = search_entities(obj_b)\n",
    "    a = res2df(a)\n",
    "    b = res2df(b)\n",
    "    ent_id_a, ent_id_b, ent_info_a, ent_info_b = get_best_pair(a, b, criteria=criteria)\n",
    "    return ent_id_a, ent_id_b, ent_info_a, ent_info_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Q28865', 'Q251')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_id_a, ent_id_b, ent_info_a, ent_info_b = strings2ids(\"python\", \"java\")\n",
    "ent_id_a, ent_id_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retreiving aspects???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on coinciding properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prop_names(ids, json):\n",
    "    prop_names = []\n",
    "    for prop_id in ids:\n",
    "        prop_names.append(json['entities'][prop_id]['labels']['en']['value'])\n",
    "    return prop_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_props(ent_info_a, ent_info_b):\n",
    "    props_a = []\n",
    "    for k in ent_info_a['claims'].keys():\n",
    "        props_a.append(k)\n",
    "        \n",
    "    props_b = []\n",
    "    for k in ent_info_b['claims'].keys():\n",
    "        props_b.append(k)\n",
    "    \n",
    "    common_props = list(set(props_a) & set(props_b))\n",
    "    uncommon_props = list(set(props_a) ^ set(props_b))\n",
    "    \n",
    "    a_json = get_entities(common_props[:50])\n",
    "    b_json = get_entities(uncommon_props[:50])\n",
    "    cp_names = get_prop_names(common_props, a_json)\n",
    "    up_names = get_prop_names(uncommon_props, b_json)\n",
    "    return cp_names, up_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inception',\n",
       " 'PSH ID',\n",
       " 'Bibliothèque nationale de France ID',\n",
       " 'instance of',\n",
       " 'Wolfram Language entity code',\n",
       " 'Stack Exchange tag',\n",
       " 'file extension',\n",
       " \"topic's main category\",\n",
       " 'official website',\n",
       " 'different from',\n",
       " 'Freebase ID',\n",
       " 'Quora topic ID',\n",
       " 'named after',\n",
       " 'YSA ID',\n",
       " 'influenced by',\n",
       " 'Microsoft Academic ID',\n",
       " 'programming paradigm',\n",
       " 'GND ID',\n",
       " 'Commons category',\n",
       " 'designed by',\n",
       " 'French Vikidia ID',\n",
       " 'typing discipline',\n",
       " 'developer',\n",
       " 'Library of Congress authority ID',\n",
       " 'copyright license',\n",
       " 'subreddit',\n",
       " 'media type',\n",
       " 'software version identifier']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FAST ID',\n",
       " 'Zhihu topic ID',\n",
       " 'part of',\n",
       " 'Biblioteca Nacional de España ID',\n",
       " 'hashtag',\n",
       " 'has quality',\n",
       " 'country of origin',\n",
       " 'Treccani ID',\n",
       " 'bug tracking system',\n",
       " 'Twitter username',\n",
       " 'mascot',\n",
       " 'NE.se ID',\n",
       " 'ESCO skill ID',\n",
       " 'subclass of',\n",
       " 'IdRef ID',\n",
       " 'movement',\n",
       " 'logo image',\n",
       " 'Techopedia ID',\n",
       " 'IRC channel',\n",
       " 'history of topic',\n",
       " 'Open Hub ID',\n",
       " 'pronunciation audio',\n",
       " 'Commons gallery',\n",
       " 'Brockhaus Enzyklopädie online ID',\n",
       " 'Dewey Decimal Classification',\n",
       " 'Store norske leksikon ID',\n",
       " 'use',\n",
       " 'source code repository',\n",
       " 'operating system',\n",
       " \"topic's main template\",\n",
       " 'Encyclopædia Britannica Online ID',\n",
       " 'BabelNet ID',\n",
       " 'GitHub username',\n",
       " 'has part',\n",
       " 'described by source',\n",
       " 'programming language']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
